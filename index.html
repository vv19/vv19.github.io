<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Vitalis Vosylius</title>

    <meta name="author" content="Vitalis Vosylius">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>
<body>
<table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p style="text-align:center">
                            <name>Vitalis Vosylius</name>
                        </p>
                        <p>
                            I am a PhD student at Imperial College London, supervised by <a
                                href="https://www.robot-learning.uk/biography"> Edward Johns</a> at <a
                                href="https://www.robot-learning.uk/"> The Robot Learning Lab</a>. My research interests
                            include robot manipulation and the broader field of robot learning.
                        </p>
                        <p>
                            Before joining Imperial for my MSc in AI and subsequently my PhD, I studied Applied Physics
                            and worked on advancing laser beam engineering techniques at the <a
                                href="https://www.ftmc.lt/en"> Center for Physical Sciences and Technology</a>.
                            I also spent time as a research intern at the Dyson Robot Learning Lab, led by <a
                                href="https://stepjam.github.io/"> Stephen James</a>.
                        </p>
                        <p>
                            Recently, I was honoured to receive the Imperial College Robotics Forum - Amazon PhD Prize for Outstanding Achievement in Robotics for my PhD research.
                        </p>
                        <p>
                            If you would like to get in touch to chat or collaborate with me, feel free to send me an
                            e-mail!
                        </p>
                        <p align=center>
                            <a href="mailto:vitalis.vosylius19@imperial.ac.uk">Email</a> &nbsp/&nbsp
                            <a href="https://scholar.google.com/citations?user=nktafp8AAAAJ&hl=en&oi=ao"
                               target="_blank">Google Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/vitalis-vosylius/" target="_blank">LinkedIn</a>
                        </p>

                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/vv.jpg"><img
                                style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;"
                                alt="profile photo" src="images/vv.jpg" class="hoverZoomLink"></a>
                    </td>
                </tr>
                </tbody>
            </table>
            <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Research</heading>
                        <p>
                            My research interests lie in the areas of robot learning and manipulation. Specifically, I
                            focus on algorithmically improving sample efficiency and generalisation capabilities of
                            imitation learning frameworks. This allows robots to acquire useful manipulation skills more
                            effectively from limited data and adapt to new tasks and settings quickly.
                        </p>
                        <p>
                            Below are some of my projects that illustrate my efforts in this area.
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                        <heading>Selected Publications</heading>
                        <p>
                        </p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/ip.gif' width="100%"/>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2411.12633">
                            <papertitle>Instant Policy: In-Context Imitation Learning via Graph Diffusion
                            </papertitle>
                        </a>
                        <br>
                        <strong>Vitalis Vosylius</strong>,
                        <a href="https://www.robot-learning.uk/biography"> Edward Johns</a>,
                        <br>
                        <em>ICLR (Oral)</em>, 2025
                        <br>
                        Winner of Best Paper Award at ICLR 2025 Robot Learning Workshop.
                        <br>
                        <a href="https://www.robot-learning.uk/instant-policy">project page</a>
                        <br>
                        <p></p>
                        <p>
                            We formulate In-Context Imitation Learning as a graph generation problem and use
                            procedurally generated pseudo-demonstrations as a main source of training data, achieving
                            manipulation skill acquisition instantaneously after the provided demonstrations.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/rendif.gif' width="100%"/>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2405.18196">
                            <papertitle>Render and Diffuse: Aligning Image and Action Spaces for Diffusion-based
                                Behaviour Cloning
                            </papertitle>
                        </a>
                        <br>
                        <strong>Vitalis Vosylius</strong>,
                        <a href="https://younggyo.me/"> Younggyo Seo</a>,
                        <a href="https://github.com/JafarAbdi/"> Jafar Uru√ß</a>,
                        <a href="https://stepjam.github.io/"> Stephen James</a>,
                        <br>
                        <em>RSS</em>, 2024
                        <br>
                        <a href="https://vv19.github.io/render-and-diffuse/">project page</a>
                        <br>
                        <p></p>
                        <p>
                            We introduce R&D, a method that integrates RGB observations with low-level actions through
                            3D renders of the robot and iteratively updates them using a learnt denoising process,
                            significantly improving learning efficiency and spatial generalisation.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/iga.gif' width="100%"/>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://openreview.net/pdf?id=CnKf9TyYtf2">
                            <papertitle>Few-Shot In-Context Imitation Learning via Implicit Graph Alignment</papertitle>
                        </a>
                        <br>
                        <strong>Vitalis Vosylius</strong>,
                        <a href="https://www.robot-learning.uk/biography"> Edward Johns</a>,
                        <br>
                        <em>CoRL</em>, 2023
                        <br>
                        <a href="https://www.robot-learning.uk/implicit-graph-alignment/">project page</a>
                        <br>
                        <p></p>
                        <p>
                            We learn how to align graph representations of objects and use it as a foundation of a
                            few-shot in-context imitation learning framework.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/dallebot.gif' width="100%"/>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2210.02438">
                            <papertitle>DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics</papertitle>
                        </a>
                        <br>
                        <strong>Vitalis Vosylius</strong>,
                        <a href="https://ivankapelyukh.com/"> Ivan Kapelyukh</a>,
                        <a href="https://www.robot-learning.uk/biography"> Edward Johns</a>,
                        <br>
                        <em>RA-Letters</em>, 2023
                        <br>
                        <a href="https://www.robot-learning.uk/dall-e-bot/">project page</a>
                        <br>
                        <p></p>
                        <p>
                            We use Web-Scale Image Diffusion Models to generate goal images for object rearrangement
                            tasks.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src='images/w2s.gif' width="100%"/>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://arxiv.org/pdf/2212.06111">
                            <papertitle>Where To Start? Transferring Simple Skills to Complex Environments</papertitle>
                        </a>
                        <br>
                        <strong>Vitalis Vosylius</strong>,
                        <a href="https://www.robot-learning.uk/biography"> Edward Johns</a>,
                        <br>
                        <em>CoRL</em>, 2022
                        <br>
                        <a href="https://www.robot-learning.uk/where-to-start/">project page</a>
                        <br>
                        <p></p>
                        <p>
                            We use graph-based affordance model to find suitable starting configurations for executing
                            different tasks in complex environments.
                        </p>
                    </td>
                </tr>
            </table>

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                <tr>
                    <td style="padding:0px">
                        <br>
                        <p style="text-align:right;font-size:small;">
                            <a href="https://github.com/jonbarron/jonbarron_website">template</a>
                    </td>
                </tr>
                </tbody>
            </table>

        </td>
    </tr>
</table>
</body>

</html>
